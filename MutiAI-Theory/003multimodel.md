# 멀티모달 Ai 이해와 발전
## 멀티모달 등장 이유
- 현실 세계의 정보
    텍스트, 이밎, 음성, 등 다양한 형태로 존재
- 기존 단일 모달 : 하나의 형태만 처리하느 한계
- 멀티 모달 : 서로 다른 모달 데이터를 도시에 이해하고 통합 처리

---
## 멀티모달 발전 과정
**이미지 이해 - ViT**
- CNN의 한계를 넘어 전역 문맥 학습
- 이미지 패치를 토큰처럼 처리

**이미지-텍스트 융합 - CLIP**
- 이미지와 텍스트를 공통 임베딩 공간에 매핑
- 이미지-텍스트 검색, 제로샷 분류 가능

**설명대화 확장 - BLIP, LLaVA**
- 이미지 설명 생성
- 대화형 시각 + 언어 모델

**완전 멀티 모달 - Qwen2.5-omni, GOT-4o**
- 텍스트 이미지 오디오 영상까지 직접 처리
- 복합 모달 입력/출력을 통합적으로 처리, 실시간 추론 및 생성

---
## Vit
### CNN의 한계
- 지역적 패턴 중심 학습 -> 전역 문백 학습에 약함
- 이미지 크기나 구조 변화시 유연성이 낮음

### Transformer의 강점
- Self-Attention -> 전역 정보 학습 강점
- 병렬 처리
- BERT, GPT 등 NLP에서 혁신적인 성과

### Vit의 핵심 개념
- 이미지를 다수의 패티로 분할 -> 텍스트의 단어처럼 처리
- 각 패치를 벡터로 전환 후 위치정보를 더해 Transformer입력
- 패치 간 전역 관계를 직접 학습

### ViT의 작동 원리
1. 이미지 패치 분할
2. 패치 벡터화
3. 토큰 추가
4. 위치 인코딩 추가
5. transformer encoder
6. mlp head

### CLS 토큰
- 이미지 전체를 종학적으로 파악한 요약 벡터
- Classification token의 약자
- transformer 입력 시 , 패치 토큰들과 함께 맨앞에 구가되는 학습 가능한 벡터
- 원래 이미지는 존재하지 않는 토큰이지만, 학습 과정에서 이미지 전체 정보를 담도록 설계됨

---
## 멀티 모달
### 멀티모달 AI란
- 서로 다른 형태의 데이터를 동시에 이해하고 처리하는 AI
- 필요성 : 현실 세계의 정보는 복합적인 형태로 존재
- 등장 배경 : 단일 모달 AI의 한게 -> 멀티 모달 모델의 필요성 대두

### 대표 활용 사례
- 이미지 검색 : 텍스트로 이미지 찾기, 이미지로 이미지 찾기
- 이미지 설명 생성
- 비디오 이해, 멀티모달 챗봇

### CLIP 
- 이미지와 텍스트를 연결하는 모델
    - 4억 개 이상의 이미지-텍스트 쌍으로 학습된 멀티모달 대표 모델
    - 이미지와 텍스트를 같은 벡터 공간에 매핑하여 서로 비교, 검색 가능하게 만듦

- 핵심 아이디어
    - 이미지 인코더 + 텍스트 인코더
    - 대조 학습으로 같은 쌍은 가깝게, 다른 쌍은 멀게