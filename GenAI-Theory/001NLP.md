# NLP - 자연어 처리
---
## 자연어 처리 이해
1. 컴퓨터가 인간의 언어를 이해, 생성, 조직할 수 있도록 하는 AI의 한 분야
2. 텍스트를 정형화된 데이터롤 바꾸는 과정 

### 자연어 처리의 어려움
1. 모호성
2. 언어의 복잡성
3. 데이터 부족 및 편향
4. 문맥 이해 (가장 중요한 부분)

### 자연어 처리 기법
- 현대 NLP 기법
    - 딥러닝 기반
    - 대규모 사전학습 모델


---
## 용어 정의
**단어**
1. 토큰(token) : 자연어를 처리하는 최소 단위(단오, 형태소, 서브 워드 등등)
2. 문장(sentence) : 여러 개의 토큰으로 구성된 단위
3. 문서(Documnet) : 여러 개의 문장으로 구성된 하나의 글
4. 말뭉치(Corpus) : 여러 개의 문서가 모인 거대한 텍스트 데이터 셋
5. 어휘(Vocab) : 말뭉치에서 등장한 중복되지 않는 토큰들의 집합

**처리**
1. 토크나이즈(Tokenize) : 텍스트를 작은 단위로 분리하는 과정
2. 형태소 분석(Morphological Analysis) : 단어를 최소단위로 나누고 품사를 분석하는 과정
3. 불용어 제거(Stopword Removal) : 분석에 불필요한 단어를 제거하는 과정
4. 임베딩(Embedding) : 단어를 숫자로 변환하여 벡터 형태로 표현하는 과정 (단어 간 의미적 유사성을 반영)


---
## 자연어 처리의 기본과정
1. 입력 테스트 수집 : 처리할 데이터를 수집하는 단계
    - 입력 수집, 데이터 크롤링 
2. 전처리 : 입력 데이터를 모델이 이해할 수 있는 형태로 변환하는 과정
    - 텍스트 정제, 형태소 분석, 토큰화
3. 특징 추출
4. 모델링
5. 출력 생성

### 토큰화
적달한 단위로 쪼개는 것 (전처리 단계)

### 벡터
- 임베딩 시 사용되는 개념
1. 크기와 방향을 가진 물리량
2. 벡터 공간에서 정의된 원소
3. 여러 개의 숫자(feature)가 모여서 하나의 개념을 표현하는 단위
- **특징공간**
feature를 표현한 공간

### 임베딩
각 토큰에 의미를 담아내는 것(특징 추출 단계)
> **컴퓨터는 텍스트를 이해할 수 없어서, 수치화하여 의미를 부여해야함**

    1. 전통적 방법 - BOW, TF-IDF (빈도 기반 수치화)
        - 단어 등장 횟수를 세는 방식, 의미적 관계 반영 어려움

    2. 분포 가설 방식 - Word2Vec, GloVe (단어 의미 반영 벡터)
        - 주변 단어들과 함께 등장하는 패턴을 학습해 의미 파악, 의미가 문맥에 따라 변하다는 점은 반영안됨

    3. 문맥을 반영하는 임베딩 - Transformer 기반, 모델의 임베딩
        - 단어 벡터를 따로 학습하지 않고, 모델 내부에서 임베딩을 직접 생성하여 사요앟는 방식


---
## LLM 모델 학습의 어려움
1. 연산 자원 및 인프라
2. 데이터 수집 및 전처리
3. 유해하거나 잘못된 데이터 생성
4. 훈련 시간 및 반복 횟수
5. 과적합 및 일반화 문제
6. 환경적 영향

### LLM 활용 방법
1. Modeling : 나의 데이터를 가지고 직접 학습 시킨다
2. API, huggingface : 모델 그대로 사용하기
3. Fine-tuning : 나의 데이터 가지고 추가 학습시키기
4. RAG : 나의 데이터 가지고 답변 시키기
