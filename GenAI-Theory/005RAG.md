# RAG
**Retrieval Augmented Generation(검색 증강 생성)**
사용자에게 질문을 받으면 지식 데이터베이스에서 답변에 필요한 문서를 검색해, 필요한 문서를 포함한 프롬프트를 생성해 언어모델에 전달하여 답변하게 만드는 것
 
- 언어모델과 같이 쓰면 다음과 같은 양상이 펼쳐짐
    1. 사용자 질문 받음
    2. 지식 데이터베이스에서 답변에 필요한 문서 검색
    3. 필요한 문서를 포함한 프롬프트 생성
    4. LLM이 답변 생성

---
## Vector DB
대규모 텍스트 데이터 및 임베딩 벡터를 저장, 검색하는 데이터베이스

**사용절차**
    1. 사용자 질문을 받음 
        - 이것을 벡터로 변환 = 임베딩
    2. 준비된 정보 데이터베이스에서 답변에 필요한 문서 검색
        - 질문 벡터와 DB내 저장된 문서 벡터와 유사도 계산
        - 가장 유사도가 높은 문서 n개 찾기
    3. 필요한 문서를 포함한 프롬프트 생성
    4. 언어모델이 답변 생성하기

---
## Loader
다양한 소스에서 문서를 불러오고 처리하는 과정을 담당, 데이터 로드 담당
- 다양한 소스 지원
- 데이터 변환 및 정제
- 효율적인 데이터 관리

---
## Splitter
긴 문서를 작은 단위인 청크로 나누는 텍스트 분리 도구, 데이터전처리인 청킹 담당
- 해당 내용은 각 로더마다 다름
    1. text -> 전체 doc
    2. pdf -> page doc
    3. csv -> 행 doc

**청킹 이유**
- 언어모델의 입력 토큰의 개수가 정해져 있기 때문
- 필요한 정보만 속아내기 위함
- 핵심 정보가 유지될 수 있는 적절한 크기로 나누는 것이 중요하기 때문

**분할 시 고려점**
- 텍스트 분할 의미
    - 독립적 의미를 갖도록 함
- 청크 크기
    - 모델의 입력 크기와 비용등을 종합적으로 고려한 최적의 크기 찾기

---
## Embedding
텍스트 데이터를 숫자로 이루어진 벡터로 변환하는 과정

**임베딩 목적**
- 텍스트를 수치적으로 표현하여 유사성을 계산하기 위함
